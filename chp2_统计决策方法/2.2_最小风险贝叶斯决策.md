### 背景

在[2.1](https://blog.csdn.net/2301_79449205/article/details/134646696)最小错误率的情况, 我们考虑的是要最小化错误率$p(e|\mathbf{x})$，从而最大化后验概率$P(\omega_i|\mathbf{x})$, 但是如果分类错误，对应造成的风险是不一样的。  
就是将样本$\mathbf{x}$分错成$\omega_1$和分错成$\omega_2$所造成的损失不同，比如将病人有病判断成无病比无病判断为有病造成的风险损失更大（因为病人将失去进一步检查而错失治疗）。  
##
接下来，我们对问题做一个表述：  
（1） 状态空间 $\Omega$ 由 c 个可能的状态（类）组成：$\Omega = \{\omega_1, \omega_2, \dots, \omega_c\}$  
（2） 对于样本$\mathbf{x}$，采取的决策组成决策空间$\mathscr{A}$，由k个决策组成，$\mathscr{A} = \{\alpha_1, \alpha_2, \dots, \alpha_k\}$, 其中$\alpha_i$代表对样本$\mathbf{x}$做出的第i种决策；同时注意这里的决策数k并不一定等于类别的个数c，即不是每一个决策都会将样本分到属于某一类，这其中还包括认为样本不属于任何一类的决策（表示拒绝决策）。  
（3） 设对属于$\omega_j$类的样本$\mathbf{x}$，采取决策$\alpha_i$所带来的损失为：
$$ \lambda(\alpha_i, \omega_j), \quad i=1,\dots, k, \quad j=1, \dots, c \tag{1}$$
式(1)被称作损失函数，代表采取决策$\alpha_i$, 将样本划分为$\omega_j$所造成的损失。  

##
有了上述的表述，我们知道给定一个样本$\mathbf{x}$, 同时给定一个决策比如$\alpha_1$, 这时对于决策$\alpha_1$所确定的不同类别造成了对应不同的损失，即$\lambda(\alpha_1, \omega_1), \lambda(\alpha_1, \omega_2),...,\lambda(\alpha_1, \omega_c)$, 对这些损失进行加权平均，这时我们就得到了所谓的条件期望损失，给定的条件是样本$\mathbf{x}$和决策$\alpha_i$, 变量是$\omega_j$, 则：
$$R(\alpha_i|\mathbf{x}) = E[\lambda(\alpha_i, \omega_j)|\mathbf{x}, \alpha_i] = \sum\limits_{j=1}^c \lambda(\alpha_i, \omega_j)P(\omega_j|\mathbf{x}) \quad i=1,2,\dots,k \tag{2}$$
式（2）代表了给定样本$\mathbf{x}$和决策$\alpha_i$, 对$\mathbf{x}$实际所属不同类别造成的损失的各种可能的平均。这个式子得到了一个样本不同决策下的条件期望损失，即
$$R(\alpha_1|\mathbf{x}), \quad R(\alpha_2|\mathbf{x}), \quad \dots, \quad R(\alpha_k|\mathbf{x}) \tag{3}
$$
如果设$\alpha(\mathbf{x})=\alpha_i$,那么上式（3）可以写成：
$$R(\alpha(\mathbf{x})|\mathbf{x}) \tag{4}$$
这就是一个样本的期望损失了，那么对于**所有样本**呢？综合的期望损失如下：
$$ R(\alpha) = E[R(\alpha(\mathbf{x})|\mathbf{x})] = \int R(\alpha(\mathbf{x})|\mathbf{x})p(\mathbf{x})d\mathbf{x} \tag{5}$$
这就是对所有样本$\mathbf{x}$, 采取决策规则$\alpha(\mathbf{x})$,造成的平均损失，即**期望风险**。

##
目标：最小化这一期望风险：
$$\min R(\alpha) = \min \int R(\alpha(\mathbf{x})|\mathbf{x})p(\mathbf{x})d\mathbf{x} \tag{6}$$
上式中，$p(\mathbf{x})$和决策无关，故
$$\min R(\alpha(\mathbf{x})|\mathbf{x}) \tag{7}$$

由$\alpha(\mathbf{x})=\alpha_i$, 所以最小化贝叶斯决策就是：
$$若R(\alpha_i|\mathbf{x}) = \min_{j=1,...,k} R(\alpha_j|\mathbf{x}), \quad 则\alpha=\alpha_i \tag{8}$$

求上式最小条件期望风险的步骤为：  
（1） 利用贝叶斯定理计算后验概率：$P(\omega_j|\mathbf{x}) = \frac{P(\mathbf{x}|\omega_j)P(\omega_j)}{P(\mathbf{x})}$   
（2） 利用决策表：求$\lambda(\alpha_i, \omega_j)P(\omega_j|\mathbf{x})$
$$=> 求R(\alpha_i|\mathbf{x}) = \sum_{j=1}^c \lambda(\alpha_i, \omega_j)P(\omega_j|\mathbf{x}), \quad i=1,2,...,k \\ 算出每个\alpha_i下的风险$$  
（3） 比较$R(\alpha_i|\mathbf{x}), \quad i=1,2,...,k$
$$=> a= \argmin_{i=1,\dots,k} R(\alpha_i|\mathbf{x})$$
##
在两类情况下，且没有拒绝，则
$$ R(\alpha_i|\mathbf{x}) = \sum\limits_{j=1}^2 \lambda(\alpha_i, \omega_j)P(\omega_j|\mathbf{x})$$
$$=> \lambda(\alpha_i, \omega_1)P(\omega_1|\mathbf{x}) + \lambda(\alpha_i, \omega_2)P(\omega_2|\mathbf{x}), \quad i=1,2 \tag{9}$$
由此我们可以得到$R(\alpha_1|\mathbf{x})$和$R(\alpha_2|\mathbf{x})$，两者选最小。得如下决策规则：
$$ R(\alpha_1|\mathbf{x}) \gtrless R(\alpha_2|\mathbf{x}), \quad \mathbf{x} \in \begin{cases}\omega_1 \\ \omega_2\end{cases} \tag{10}$$
使用$\lambda_{11}$表示$\lambda(\alpha_1, \omega_1)$, 则有：
$$=> \lambda_{11}P(\omega_1|\mathbf{x})+\lambda_{12}P(\omega_2|\mathbf{x}) \gtrless \lambda_{21}P(\omega_1|\mathbf{x}) + \lambda_{22}P(\omega_2|\mathbf{x}), \quad \mathbf{x}\in \begin{cases}\omega_1 \\ \omega_2\end{cases}$$
$$=> (\lambda_{11}-\lambda_{21})P(\omega_1|\mathbf{x}) \gtrless (\lambda_{22}-\lambda_{12})P(\omega_2|\mathbf{x})  $$
假设$\lambda_{11}<\lambda_{21},\quad \lambda_{22}<\lambda_{12}$,即决策对的风险总是小于决策错的，
$$=> \frac{P(\omega_1|\mathbf{x})}{P(\omega_2|\mathbf{x})} = \frac{P(\mathbf{x}|\omega_1)P(\omega_1)}{P(\mathbf{x}|\omega_2)P(\omega_2)} \gtrless \frac{\lambda_{22}-\lambda_{12}}{\lambda_{11}-\lambda_{21}} $$
$$=> \frac{P(\mathbf{x}|\omega_1)}{P(\mathbf{x}|\omega_2)} \gtrless \frac{(\lambda_{22}-\lambda_{12})P(\omega_2)}{(\lambda_{11}-\lambda_{21})P(\omega_1)}=c, \quad \mathbf{x} \in \begin{cases}\omega_1 \\ \omega_2\end{cases} \tag{11}$$

令$l(\mathbf{x})=\frac{P(\mathbf{x}|\omega_1)}{P(\mathbf{x}|\omega_2)}$，这是似然比函数，可以看到，当$\lambda_{11}=\lambda_{22}=0$时，这是决策对了没有损失，且当$\lambda_{12}=\lambda_{21}=c$, 两种决策错了损失相同，那么这时就相当于不用考虑不同决策造成的风险问题，因为此时风险都一致，这就和最小错误率的情况一致了，依然是最大化后验概率。
##
本节考虑了在有风险的情况下，该选择什么样的决策，同时我们也发现，在风险一致的情况下，最小风险贝叶斯决策就是最小错误率贝叶斯决策。